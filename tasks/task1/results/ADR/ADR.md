# Переход Hotelio от монолита к микросервисам (инкремент 1)

**Автор:** Минлигареев Максим

**Дата:** 11.11.2025

---

## Контекст
Существующая система — Java Spring Boot монолит с единой БД PostgreSQL. Основные домены: Booking, User, Hotel, PromoCode, Review. Монолит экспонирует REST-эндпоинты для клиентов и партнёров; Booking синхронно валидирует пользователя, отель, промокод и отзывы, рассчитывает цену/скидку и сохраняет бронирование.

Ключевые проблемы: трудная поддержка и релизы, низкая гибкость масштабирования (особенно под нагрузки бронирования), общий деплой и БД, сильная связанность модулей, REST не оптимален под разные фронтенды.

Целевое состояние курса: поэтапная миграция по Strangler Fig; через год — полный микросервисный ландшафт, service mesh, метрики/трейсинг, Kafka на масштаб, GraphQL-BFF. В этом ADR описываем промежуточное состояние (2–3 месяца).

---

## Функциональные требования (выдержка)
1. Создание бронирования: `POST /api/bookings?userId&hotelId[&promoCode]`.
2. Получение бронирований: `GET /api/bookings[?userId]`.
3. Проверки пользователя: `GET /api/users/{id}`, `/status`, `/blacklisted`, `/active`, `/authorized`, `/vip`.
4. Данные отеля: `GET /api/hotels/...` (включая фильтры и выборки).
5. Проверка промокодов и влияние отзывов на возможность брони.

---

## Нефункциональные требования
- Инкрементальность (Strangler Fig), совместимость API на первом шаге.
- Масштабируемость чтений (User/Hotel) и критического пути бронирования.
- Независимые релизы команд; подготовка к GitOps/mesh.
- Наблюдаемость: метрики HTTP/JDBC, трассировка (OpenTelemetry), корреляция запросов.
- Пошаговое разделение БД.

---

## Решение (инкремент 1)

### Что выносим первыми
- **User Service** — чёткая граница (`app_user`), read-heavy проверки статусов; уменьшает связность Booking.
- **Hotel Service** — преобладают чтения; хорошо кешируется и масштабируется.

> Booking оставляем в монолите на этот этап: он оркестрирует все проверки и делает запись — самый связанный компонент. После выноса зависимостей его мигрировать проще и безопаснее.

### Паттерн миграции
- **Strangler Fig + API Gateway**: маршрутизируем `/api/users/**` и `/api/hotels/**` в новые сервисы, остальное — в монолит.
- **ACL к БД**: на фазе 1 новые сервисы читают из схемы монолита через свои репозитории/адаптеры (без прямой зависимости доменной логики от схемы).
- **Разделение БД (фаза 2)**: поднимаем `user-db` и `hotel-db`, мигрируем данные, переключаем чтение/запись; монолит для User/Hotel переходит на REST-клиенты.
- **Наблюдаемость/устойчивость**: `X-Request-Id`, ретраи, таймауты, circuit-breakers, алерты по 5xx и латентности.

### C4-диаграммы
- C1 — контекст: `diagram/C1-interim.puml`
- C2 — контейнеры: `diagram/C2-interim.puml`

---

## План работ (8–10 недель)
1. **Edge/Observability**: API Gateway, access-logs, `X-Request-Id`, базовые дашборды.
2. **User Service (фаза 1)**: реализовать все текущие `/api/users/**`, интеграция с монолитной БД через ACL; переключить маршрут на сервис.
3. **Hotel Service (фаза 1)**: реализовать `/api/hotels/**`, добавить кеширование для популярных выборок; переключить маршрут.
4. **Монолит → внешние вызовы**: заменить DAO пользователей/отелей на `UserClient`/`HotelClient` (таймауты/ретраи/circuit-breaker).
5. **Разделение БД (фаза 2)**: поднять `user-db` и `hotel-db`, миграция данных и переключение; удалить прямые доступы монолита к `app_user`/`hotel`.
6. **Наблюдаемость/надёжность**: метрики HTTP/JDBC, трассировка, алерты; хаос-тесты деградаций User/Hotel.
7. **Подготовка инкремента 2**: вынос Promo/Review, подготовка к выносу Booking, проектирование событий Kafka `BookingCreated`.

---

## Альтернативы
1) Выносить Booking первым — высокий риск, много интеграций/транзакций.
2) Сразу вводить событийную интеграцию (CDC/Kafka) — усложняет первый шаг; добавим после стабилизации REST-контрактов.
3) Вынос Promo первым — меньший эффект на масштабирование критического пути.

---

## Риски и ограничения
- На фазе 1 сервисы читают из общей БД — зависимость от схемы; смягчаем ACL и тестами контрактов.
- Появляются сетевые зависимости в critical-path — таймауты/ретраи/CB обязательны.
- После разделения БД нужна консистентность справочников и кросс-ссылок (миграции + при необходимости CDC).
- Больше сервисов ⇒ больше пайплайнов, мониторинга и алертов (компенсируется GitOps/mesh).

---

## Артефакты
- Этот ADR: `task1/results/ADR/adr.md`
- PlantUML: `task1/results/ADR/diagram/C1-interim.puml`, `task1/results/ADR/diagram/C2-interim.puml`
- Логи проверки API: `task1/results/test-log.txt`